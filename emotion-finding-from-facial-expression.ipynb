{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n #       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T06:41:02.038525Z","iopub.execute_input":"2022-03-16T06:41:02.039126Z","iopub.status.idle":"2022-03-16T06:41:02.065798Z","shell.execute_reply.started":"2022-03-16T06:41:02.039038Z","shell.execute_reply":"2022-03-16T06:41:02.065068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folderName = os.path.split(os.path.split(\"../input/facial-expression-dataset/test/test/angry\")[1])[-1]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:02.148961Z","iopub.execute_input":"2022-03-16T06:41:02.149503Z","iopub.status.idle":"2022-03-16T06:41:02.155154Z","shell.execute_reply.started":"2022-03-16T06:41:02.149468Z","shell.execute_reply":"2022-03-16T06:41:02.154251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folderName","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:02.157333Z","iopub.execute_input":"2022-03-16T06:41:02.157663Z","iopub.status.idle":"2022-03-16T06:41:02.171336Z","shell.execute_reply.started":"2022-03-16T06:41:02.157622Z","shell.execute_reply":"2022-03-16T06:41:02.170345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_data = \"../input/facial-expression-dataset/train/train/\"\n\n\n\n\nimport os\nimg_dirs = []\nfor entry in os.scandir(path_to_data):\n    if entry.is_dir():\n        img_dirs.append(entry.path)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:02.17356Z","iopub.execute_input":"2022-03-16T06:41:02.174041Z","iopub.status.idle":"2022-03-16T06:41:02.190398Z","shell.execute_reply.started":"2022-03-16T06:41:02.173986Z","shell.execute_reply":"2022-03-16T06:41:02.189757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = {}\nfor img_dir in img_dirs:\n    emotion_name = img_dir.split('/')[-1]\n    file_list = []\n    for entry in os.scandir(img_dir):\n        file_list.append(entry.path)\n    emotion[emotion_name] = file_list\nemotion","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:02.192195Z","iopub.execute_input":"2022-03-16T06:41:02.193073Z","iopub.status.idle":"2022-03-16T06:41:04.499403Z","shell.execute_reply.started":"2022-03-16T06:41:02.193027Z","shell.execute_reply":"2022-03-16T06:41:04.498463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:04.501136Z","iopub.execute_input":"2022-03-16T06:41:04.50207Z","iopub.status.idle":"2022-03-16T06:41:40.658455Z","shell.execute_reply.started":"2022-03-16T06:41:04.502021Z","shell.execute_reply":"2022-03-16T06:41:40.648944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_dict = {}\ncount = 0\nfor emotion_name in emotion.keys():\n    class_dict[emotion_name] = count\n    count = count + 1\nclass_dict","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:40.659858Z","iopub.execute_input":"2022-03-16T06:41:40.660075Z","iopub.status.idle":"2022-03-16T06:41:40.672179Z","shell.execute_reply.started":"2022-03-16T06:41:40.660048Z","shell.execute_reply":"2022-03-16T06:41:40.671114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pywt\nimport cv2    \n\ndef w2d(img, mode='haar', level=1):\n    imArray = img\n    #Datatype conversions\n    #convert to grayscale\n    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n    #convert to float\n    imArray =  np.float32(imArray)   \n    imArray /= 255;\n    # compute coefficients \n    coeffs=pywt.wavedec2(imArray, mode, level=level)\n\n    #Process Coefficients\n    coeffs_H=list(coeffs)  \n    coeffs_H[0] *= 0;  \n\n    # reconstruction\n    imArray_H=pywt.waverec2(coeffs_H, mode);\n    imArray_H *= 255;\n    imArray_H =  np.uint8(imArray_H)\n\n    return imArray_H","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:40.674469Z","iopub.execute_input":"2022-03-16T06:41:40.674921Z","iopub.status.idle":"2022-03-16T06:41:41.294428Z","shell.execute_reply.started":"2022-03-16T06:41:40.674872Z","shell.execute_reply":"2022-03-16T06:41:41.29356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nX, y = [], []\nfor emotion_name, training_files in emotion.items():\n    for training_image in training_files:\n        img = cv2.imread(training_image)\n        scalled_raw_img = cv2.resize(img, (32, 32))\n        img_har = w2d(img,'db1',5)\n        scalled_img_har = cv2.resize(img_har, (32, 32))\n        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n        X.append(combined_img)\n        y.append(class_dict[emotion_name]) ","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:41:41.295727Z","iopub.execute_input":"2022-03-16T06:41:41.296196Z","iopub.status.idle":"2022-03-16T06:45:29.340536Z","shell.execute_reply.started":"2022-03-16T06:41:41.296152Z","shell.execute_reply":"2022-03-16T06:45:29.33984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X[0])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:45:29.341662Z","iopub.execute_input":"2022-03-16T06:45:29.341883Z","iopub.status.idle":"2022-03-16T06:45:29.349418Z","shell.execute_reply.started":"2022-03-16T06:45:29.341858Z","shell.execute_reply":"2022-03-16T06:45:29.348529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:45:29.350831Z","iopub.execute_input":"2022-03-16T06:45:29.351551Z","iopub.status.idle":"2022-03-16T06:45:29.361199Z","shell.execute_reply.started":"2022-03-16T06:45:29.35151Z","shell.execute_reply":"2022-03-16T06:45:29.360537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:45:29.362643Z","iopub.execute_input":"2022-03-16T06:45:29.363572Z","iopub.status.idle":"2022-03-16T06:45:29.372521Z","shell.execute_reply.started":"2022-03-16T06:45:29.363481Z","shell.execute_reply":"2022-03-16T06:45:29.371623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X).reshape(len(X),4096).astype(float)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:45:29.373899Z","iopub.execute_input":"2022-03-16T06:45:29.37437Z","iopub.status.idle":"2022-03-16T06:45:29.788425Z","shell.execute_reply.started":"2022-03-16T06:45:29.374341Z","shell.execute_reply":"2022-03-16T06:45:29.787664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:45:29.790725Z","iopub.execute_input":"2022-03-16T06:45:29.790958Z","iopub.status.idle":"2022-03-16T06:45:30.525666Z","shell.execute_reply.started":"2022-03-16T06:45:29.790933Z","shell.execute_reply":"2022-03-16T06:45:30.524804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\npipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\npipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:45:30.527085Z","iopub.execute_input":"2022-03-16T06:45:30.527544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, pipe.predict(X_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nmodel_params = {\n    'svm': {\n        'model': svm.SVC(gamma='auto',probability=True),\n        'params' : {\n            'svc__C': [1,10,100,1000],\n            'svc__kernel': ['rbf','linear']\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'randomforestclassifier__n_estimators': [1,5,10]\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'logisticregression__C': [1,5,10]\n        }\n    }\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\nbest_estimators = {}\nimport pandas as pd\nfor algo, mp in model_params.items():\n    pipe = make_pipeline(StandardScaler(), mp['model'])\n    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n    clf.fit(X_train, y_train)\n    scores.append({\n        'model': algo,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    best_estimators[algo] = clf.best_estimator_\n    \ndf = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators['svm'].score(X_test,y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators['random_forest'].score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators['logistic_regression'].score(X_test,y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_clf = best_estimators['svm']\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, best_clf.predict(X_test))\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sn\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install joblib\nimport joblib \n# Save the model as a pickle in a file \njoblib.dump(best_clf, 'saved_model.pkl') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open(\"class_dictionary.json\",\"w\") as f:\n    f.write(json.dumps(class_dict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}